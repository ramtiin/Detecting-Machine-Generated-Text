{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o5-jnesFKbb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "HC3_filtered = pd.concat([pd.read_hdf('/content/drive/MyDrive/HC3 - filtered/GPT_df_3.h5'), pd.read_hdf('/content/drive/MyDrive/HC3 - filtered/Human_df_3.h5')], axis=0).fillna(0)\n",
        "GPT_2 = pd.concat([pd.read_hdf('/content/drive/MyDrive/GPT2/GPT_df_gpt2.h5'), pd.read_hdf('/content/drive/MyDrive/GPT2/Human_df_gpt2.h5')], axis=0).fillna(0)\n",
        "HC3_unfiltered = pd.concat([pd.read_hdf('/content/drive/MyDrive/HC3 - Unfiltered/GPT_df_3.h5'), pd.read_hdf('/content/drive/MyDrive/HC3 - Unfiltered/Human_df_3.h5')], axis=0).fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BNmXaW2IAIh"
      },
      "outputs": [],
      "source": [
        "# Replacement dictionary\n",
        "replacement_dict = {\n",
        "    'Human_train': 'train',\n",
        "    'Human_test': 'test',\n",
        "    'Human_val': 'val',\n",
        "    'GPT_train': 'train',\n",
        "    'GPT_test': 'test',\n",
        "    'GPT_val': 'val'\n",
        "}\n",
        "\n",
        "# Apply the replacements\n",
        "GPT_2 = GPT_2.replace(replacement_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gYa2NbSMmar"
      },
      "outputs": [],
      "source": [
        "# Create the datasets dictionary\n",
        "datasets = {\n",
        "    'HC3_filtered': HC3_filtered,\n",
        "    'HC3_unfiltered': HC3_unfiltered,\n",
        "     'GPT_2': GPT_2\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49V6AEY4GsVi",
        "outputId": "436bb61b-3204-4314-8e8a-58e99599db3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on HC3_filtered, Testing on HC3_filtered\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97     16148\n",
            "           1       0.96      0.93      0.94      8012\n",
            "\n",
            "    accuracy                           0.96     24160\n",
            "   macro avg       0.96      0.96      0.96     24160\n",
            "weighted avg       0.96      0.96      0.96     24160\n",
            "\n",
            "Training on HC3_filtered, Testing on HC3_unfiltered\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97     16580\n",
            "           1       0.94      0.92      0.93      8014\n",
            "\n",
            "    accuracy                           0.96     24594\n",
            "   macro avg       0.95      0.95      0.95     24594\n",
            "weighted avg       0.96      0.96      0.96     24594\n",
            "\n",
            "Training on HC3_filtered, Testing on GPT_2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.93      0.66      5000\n",
            "           1       0.64      0.12      0.20      5000\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.58      0.53      0.43     10000\n",
            "weighted avg       0.58      0.53      0.43     10000\n",
            "\n",
            "Training on HC3_unfiltered, Testing on HC3_filtered\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     16148\n",
            "           1       0.96      0.92      0.94      8012\n",
            "\n",
            "    accuracy                           0.96     24160\n",
            "   macro avg       0.96      0.95      0.96     24160\n",
            "weighted avg       0.96      0.96      0.96     24160\n",
            "\n",
            "Training on HC3_unfiltered, Testing on HC3_unfiltered\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     16580\n",
            "           1       0.96      0.93      0.94      8014\n",
            "\n",
            "    accuracy                           0.96     24594\n",
            "   macro avg       0.96      0.95      0.96     24594\n",
            "weighted avg       0.96      0.96      0.96     24594\n",
            "\n",
            "Training on HC3_unfiltered, Testing on GPT_2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.93      0.67      5000\n",
            "           1       0.66      0.13      0.22      5000\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.59      0.53      0.44     10000\n",
            "weighted avg       0.59      0.53      0.44     10000\n",
            "\n",
            "Training on GPT_2, Testing on HC3_filtered\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.58      0.68     16148\n",
            "           1       0.47      0.73      0.57      8012\n",
            "\n",
            "    accuracy                           0.63     24160\n",
            "   macro avg       0.64      0.66      0.62     24160\n",
            "weighted avg       0.70      0.63      0.64     24160\n",
            "\n",
            "Training on GPT_2, Testing on HC3_unfiltered\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.57      0.67     16580\n",
            "           1       0.45      0.73      0.56      8014\n",
            "\n",
            "    accuracy                           0.63     24594\n",
            "   macro avg       0.64      0.65      0.62     24594\n",
            "weighted avg       0.70      0.63      0.64     24594\n",
            "\n",
            "Training on GPT_2, Testing on GPT_2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82      5000\n",
            "           1       0.82      0.81      0.82      5000\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "f1_results = []\n",
        "\n",
        "for train_name, train_df in datasets.items():\n",
        "    # Define the columns based on the training dataset\n",
        "    feature_cols = train_df.drop(['source', 'text', 'label'], axis=1).columns.tolist()\n",
        "\n",
        "    # Prepare train data\n",
        "    X_train = train_df[train_df['source'].isin(['train'])][feature_cols]\n",
        "    y_train = train_df[train_df['source'].isin(['train'])]['label']\n",
        "\n",
        "    X_val = train_df[train_df['source'].isin(['val'])][feature_cols]\n",
        "    y_val = train_df[train_df['source'].isin(['val'])]['label']\n",
        "\n",
        "    # Train model\n",
        "    clf = xgb.XGBClassifier(eval_metric=\"error\", early_stopping_rounds=15)\n",
        "    evals = [(X_train, y_train), (X_val, y_val)]\n",
        "    clf.fit(X_train, y_train, eval_set=evals, verbose=False)\n",
        "\n",
        "    for test_name, test_df in datasets.items():\n",
        "        # Ensure test dataset has same columns as train dataset\n",
        "        X_test = test_df[test_df['source'].isin(['test'])][feature_cols]\n",
        "        y_test = test_df[test_df['source'].isin(['test'])]['label']\n",
        "\n",
        "        # Predict\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Compute F1 score (binary classification)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        # Append results to the f1_results list\n",
        "        f1_results.append((train_name, test_name, f1))\n",
        "\n",
        "        print(f\"Training on {train_name}, Testing on {test_name}\")\n",
        "        print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC1ZT3mMgu7Y",
        "outputId": "cd988baf-aa01-49e2-fa86-4818f12ecb1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Training Set     Testing Set  F1 Score\n",
            "0    HC3_filtered    HC3_filtered  0.944307\n",
            "1    HC3_filtered  HC3_unfiltered  0.934174\n",
            "2    HC3_filtered           GPT_2  0.200978\n",
            "3  HC3_unfiltered    HC3_filtered  0.942168\n",
            "4  HC3_unfiltered  HC3_unfiltered  0.941886\n",
            "5  HC3_unfiltered           GPT_2  0.220336\n",
            "6           GPT_2    HC3_filtered  0.570016\n",
            "7           GPT_2  HC3_unfiltered  0.561056\n",
            "8           GPT_2           GPT_2  0.817926\n"
          ]
        }
      ],
      "source": [
        "# Convert f1_results to DataFrame\n",
        "df_f1 = pd.DataFrame(f1_results, columns=[\"Training Set\", \"Testing Set\", \"F1 Score\"])\n",
        "print(df_f1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
